{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = r'C:\\Users\\Titouan\\Desktop\\Github\\Paren\\data\\evsession_095_data_20240131.csv'\n",
    "\n",
    "\n",
    "def convert_csv(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def filter_data(data, month = 1 , cities = ['San Jose', 'Denver', 'Chicago']):\n",
    "    \n",
    "    # Convert 'last_updated' from Unix timestamp to datetime (if your column is named differently, change accordingly)\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    # Filter for the specific cities\n",
    "    city_filter = data['city'].isin(cities)\n",
    "    \n",
    "    # Filter for January\n",
    "    january_filter = data['date'].dt.month == month\n",
    "    \n",
    "    # Apply filters\n",
    "    filtered_data = data[city_filter & january_filter]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "filtered_data = filter_data(convert_csv(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we created 2 functions the first simply reads the csv file and converts it to a pandas Dataframe, the second filters the data by date and city.\n",
    "We could have continued using all the data at first but I chose to work with the filtered data as it is a lot less memory heavy and reduces the run time of my algorithms as it takes multiple seconds on my computer to do the filter operation.\n",
    "\n",
    "\n",
    "Our objective is to analyze the charging session and failure data from the 3 cities, Chicago,IL,  Denver,CO, and San Jose, CA for the month of January.\n",
    "We want to know over what time period was there a large deviation in charger performance? And in what city was the change the most noticeable?\n",
    "Finally we will try to find what other data we could use to correlate our findings?\n",
    "\n",
    "To awnser the first  part of this problem I created performance scores:\n",
    "    1. success rate which represents the success rate of charging sessions \n",
    "    2. avg charge time which as stated looks at the average charge time of succesful sessions\n",
    "    3. retry rate which measures the proportion of succesful sessions with retries over the total amount of succesful sessions\n",
    "    4. replug_ccs which represents the proportion of ccs sessions with replugs with retries over the total amount of succesful ccs sessions\n",
    "    5. short session proportion which represents the number of short sessions divided by the total amount of sessions\n",
    "    6. Charger availability caluclates the proportion of time the charger is available and not infered as offline or detected offline\n",
    "\n",
    "After creating these indicators we want to try to observe a deviation to do so we will measure there moving average and moving standard deviation over time.\n",
    "\n",
    "\n",
    "Below I created multiple different functions that will help me plot these:\n",
    "\n",
    "    calculate_metrics will output the standard deviation and the average of these performance indicator for each date\n",
    "\n",
    "    filter_significant_deviations will filter the rows that have a high deviation either from the mean \n",
    "\n",
    "    calculate_metrics_avg_rolling outputs the rolling average of the data given\n",
    "\n",
    "    both plot metrics and finalize plot are quite specific and simplify the plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_metrics_avg_rolling(data,columns = ['success_rate', 'avg_charge_time', 'retry_rate', 'replug_rate_ccs', 'availability', 'short_session_proportion'], window_size=7):\n",
    "\n",
    "    # Ensure data is sorted by date\n",
    "    data = data.sort_values('date')\n",
    "\n",
    "    # Calculate daily mean\n",
    "    daily_mean = data.groupby('date')[columns].mean()\n",
    "    daily_std = data.groupby('date')[columns].std()\n",
    "\n",
    "    # Initialize a DataFrame to hold the rolling statistics\n",
    "    rolling_stats = pd.DataFrame(index=daily_mean.index)\n",
    "\n",
    "    # Calculate rolling means and standard deviations using the full dataset\n",
    "    for column in columns:\n",
    "        # Calculate rolling mean and standard deviation of daily means\n",
    "        rolling_mean = daily_mean[column].rolling(window=window_size, min_periods=1).mean()\n",
    "        if daily_std[column].isna().all(): rolling_std = daily_mean[column].rolling(window=window_size, min_periods=1).std()\n",
    "        else: rolling_std = daily_std[column].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "        # Assign to rolling stats DataFrame\n",
    "        rolling_stats[f'{column}_rolling_avg'] = rolling_mean\n",
    "        rolling_stats[f'{column}_rolling_std'] = rolling_std\n",
    "\n",
    "    # Reset the index and include the date\n",
    "    rolling_stats.reset_index(inplace=True)\n",
    "\n",
    "    return rolling_stats\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(data, city=None, station=None, window_size = 7):\n",
    "    if city:\n",
    "        data = data[data['city'] == city].copy()\n",
    "    if station:\n",
    "        data = data[data['name'] == station].copy()\n",
    "\n",
    "    data.loc[:, 'total_success'] = data['charges_ccs'] + data['charges_cha']\n",
    "    data.loc[:, 'total_failures'] = data['fails_ccs'] + data['fails_cha']\n",
    "    data.loc[:, 'total_sessions'] = data['total_success'] + data['total_failures']\n",
    "\n",
    "    # Prevent division by zero by adding small epsilon where total_sessions is zero\n",
    "    data.loc[:, 'success_rate'] = np.where(data['total_sessions']>0,data['total_success'] / (data['total_sessions']),0)\n",
    "    data.loc[:, 'avg_charge_time'] = (data['avg_charge_ccs'] * data['charges_ccs'] + data['avg_charge_cha'] * data['charges_cha']) / (data['total_success'] + np.finfo(float).eps)\n",
    "    data.loc[:, 'retry_rate'] = (data['retries_ccs'] + data['retries_cha']) / (data['total_success'] + np.finfo(float).eps)\n",
    "    data.loc[:, 'replug_rate_ccs'] = data['replugs_ccs'] / (data['charges_ccs'] + np.finfo(float).eps)\n",
    "    data.loc[:, 'availability'] = data['open_secs'] / (data['open_secs'] + data['detected_dt_p1'] + data['detected_dt_p2'] + data['inferred_dt_p1'] + data['inferred_dt_p2'] + np.finfo(float).eps)\n",
    "\n",
    "    short_session_columns = [f'bin_{i}_ccs' for i in range(1, 10)] + [f'bin_{i}_cha' for i in range(1, 10)]\n",
    "    data['short_session_total'] = data[short_session_columns].sum(axis=1)\n",
    "    long_session_columns = [f'bin_{i}_ccs' for i in [10, 20, 30, 40, 50, 60, 75, 90, 120]] + [f'bin_{i}_cha' for i in [10, 20, 30, 40, 50, 60, 75, 90, 120]]\n",
    "    data['long_session_total'] = data[long_session_columns].sum(axis=1)\n",
    "\n",
    "    data.loc[:, 'short_session_proportion'] = data['short_session_total'] / (data['short_session_total'] + data['long_session_total'] + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "    \n",
    "    daily_averages = calculate_metrics_avg_rolling(data,window_size=window_size)\n",
    "\n",
    "    return daily_averages\n",
    "\n",
    "\n",
    "def filter_significant_deviations(data, column='success_rate', window_size=7, threshold=2, outlier_type='all'):\n",
    "    \"\"\"\n",
    "    Filters significant deviations based on a specified column and criteria,\n",
    "    without modifying the original DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a copy of the data to work on\n",
    "    working_data = data.copy()\n",
    "\n",
    "    # Compute new columns based on the original data\n",
    "    working_data['total_success'] = working_data['charges_ccs'] + working_data['charges_cha']\n",
    "    working_data['total_failures'] = working_data['fails_ccs'] + working_data['fails_cha']\n",
    "    working_data['total_sessions'] = working_data['total_success'] + working_data['total_failures']\n",
    "\n",
    "    if column == 'success_rate':\n",
    "        working_data['success_rate'] = np.where(working_data['total_sessions'] > 0,\n",
    "                                                working_data['total_success'] / (working_data['total_sessions']), 0)\n",
    "    if column == 'avg_charge_time':\n",
    "        working_data['avg_charge_time'] = (working_data['avg_charge_ccs'] * working_data['charges_ccs'] + working_data['avg_charge_cha'] * working_data['charges_cha']) / (working_data['total_success'] + np.finfo(float).eps)\n",
    "    if column == 'retry_rate':\n",
    "        working_data['retry_rate'] = (working_data['retries_ccs'] + working_data['retries_cha']) / (working_data['total_success'] + np.finfo(float).eps)\n",
    "    if column == 'replug_rate_ccs':\n",
    "        working_data['replug_rate_ccs'] = working_data['replugs_ccs'] / (working_data['charges_ccs'] + np.finfo(float).eps)\n",
    "    if column == 'availability':\n",
    "        working_data['availability'] = working_data['open_secs'] / (working_data['open_secs'] + working_data['detected_dt_p1'] +\n",
    "                                                                    working_data['detected_dt_p2'] + working_data['inferred_dt_p1'] +\n",
    "                                                                    working_data['inferred_dt_p2'] + np.finfo(float).eps)\n",
    "    if column == 'short_session_proportion':\n",
    "        short_session_columns = [f'bin_{i}_ccs' for i in range(1, 10)] + [f'bin_{i}_cha' for i in range(1, 10)]\n",
    "        working_data['short_session_total'] = working_data[short_session_columns].sum(axis=1)\n",
    "        long_session_columns = [f'bin_{i}_ccs' for i in [10, 20, 30, 40, 50, 60, 75, 90, 120]] + \\\n",
    "                               [f'bin_{i}_cha' for i in [10, 20, 30, 40, 50, 60, 75, 90, 120]]\n",
    "        working_data['long_session_total'] = working_data[long_session_columns].sum(axis=1)\n",
    "        working_data['short_session_proportion'] = working_data['short_session_total'] /(working_data['short_session_total'] + working_data['long_session_total'] + np.finfo(float).eps)\n",
    "\n",
    "    # Ensure data is sorted by date\n",
    "    working_data = working_data.sort_values('date')\n",
    "    # Calculate daily mean\n",
    "    working_data['daily_mean'] = working_data.groupby('date')[column].transform('mean')\n",
    "\n",
    "    # Calculate daily standard deviation and broadcast it back to the original DataFrame's shape\n",
    "    working_data['daily_std'] = working_data.groupby('date')[column].transform('std')           \n",
    "\n",
    "\n",
    "    # Calculate rolling mean and standard deviation of daily means\n",
    "    working_data[f'{column}_rolling_mean']= working_data['daily_mean'].rolling(window=window_size, min_periods=1).mean()\n",
    "    \n",
    "    working_data[f'{column}_rolling_std'] = working_data['daily_std'].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "\n",
    "    # Calculate the upper and lower bounds\n",
    "    working_data['upper_bound'] = working_data[f'{column}_rolling_mean'] + (threshold * working_data[f'{column}_rolling_std'])\n",
    "    working_data['lower_bound'] = working_data[f'{column}_rolling_mean'] - (threshold * working_data[f'{column}_rolling_std'])\n",
    "\n",
    "    \n",
    "\n",
    "    # Create masks based on the outlier detection method\n",
    "    mask = None\n",
    "    if outlier_type == 'not':\n",
    "        mask = (working_data[column] <= working_data['upper_bound']) & (working_data[column] >= working_data['lower_bound'])\n",
    "    elif outlier_type == 'all':\n",
    "        mask = (working_data[column] > working_data['upper_bound']) | (working_data[column] < working_data['lower_bound'])\n",
    "    elif outlier_type == 'low':\n",
    "        mask = working_data[column] < working_data['lower_bound']\n",
    "    else:  # Assuming 'high'\n",
    "        mask = working_data[column] > working_data['upper_bound']\n",
    "\n",
    "    # Apply the mask to the original data and return modified data\n",
    "    data = data.loc[mask]\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def plot_metrics(data, axs, label_prefix,color):\n",
    "    metrics = ['success_rate', 'avg_charge_time', 'retry_rate', 'replug_rate_ccs', 'availability', 'short_session_proportion']\n",
    "    metric_names = ['Success Rate', 'Charge Time', 'Retry Rate', 'Replug Rate','Short Session Proportion','Availability']\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axs[2*i].plot(data['date'], data[f'{metric}_rolling_avg'], label=f'Avg {metric_names[i]} - {label_prefix}', color=color)\n",
    "        axs[2*i + 1].plot(data['date'], data[f'{metric}_rolling_std'], label=f'Std Dev {metric_names[i]} - {label_prefix}', color=color)\n",
    "\n",
    "def finalize_plots(axs):\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.legend()\n",
    "    axs[0].set_ylabel('Success Rate')\n",
    "    axs[2].set_ylabel('Charge Time')\n",
    "    axs[4].set_ylabel('Retry Rate')\n",
    "    axs[6].set_ylabel('Replug Rate')\n",
    "    axs[8].set_ylabel('Short Session Proportion')\n",
    "    axs[10].set_ylabel('Availability')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics_std_avg_multi(data, window_size=7, cities=None, stations=None, filter = False, threshold = 2, filter_column = \"success_rate\",outlier_type = 'all'):\n",
    "    fig, axs = plt.subplots(12, 1, figsize=(10, 40))\n",
    "\n",
    "    colors = ['blue', 'red', 'green', 'magenta', 'yellow', 'orange', 'purple', 'pink',\n",
    "        'lime', 'cyan', 'brown', 'gray', 'olive', 'maroon', 'navy', 'teal',\n",
    "        'aqua', 'coral', 'fuchsia', 'gold', 'indigo', 'khaki', 'lavender',\n",
    "        'plum', 'salmon', 'tan', 'violet', 'azure', 'beige', 'bisque',]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    if cities and len(cities) == 1 and not stations:\n",
    "        city = cities[0]\n",
    "        data = filter_data(data,cities=cities)\n",
    "        if filter : filt_data = filter_significant_deviations(data,filter_column, window_size ,threshold,outlier_type)\n",
    "        stations = filt_data[filt_data['city'] == city]['name'].unique()\n",
    "        for station in stations:\n",
    "            station_data = calculate_metrics(data, city, station, window_size = window_size)\n",
    "            plot_metrics(station_data, axs, station,colors[i])\n",
    "            i+=1\n",
    "    elif cities:\n",
    "        for city in cities:\n",
    "            city_data = calculate_metrics(data, city, window_size = window_size)\n",
    "            plot_metrics(city_data, axs, city,colors[i])\n",
    "            i+=1\n",
    "    elif not cities:\n",
    "        general_data = calculate_metrics(data, window_size = window_size)\n",
    "        plot_metrics(general_data, axs, 'total',colors[i])\n",
    "        i+=1\n",
    "    elif stations:\n",
    "        for station in stations:\n",
    "            station_data = calculate_metrics(data, cities[0], station, window_size = window_size)\n",
    "            plot_metrics(station_data, axs, station,colors[i])\n",
    "            i+=1\n",
    "\n",
    "    finalize_plots(axs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_std_avg_multi(filtered_data, cities=['San Jose','Denver','Chicago'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_std_avg_multi(filtered_data,window_size= 2, cities=['San Jose','Denver','Chicago'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of plots:\n",
    "\n",
    "We have generated plots for three different rolling windows: 7 days, 4 days, and 2 days. In our initial analysis, we noted that San Jose shows no significant performance deviations compared to Denver and Chicago.\n",
    "\n",
    "Significantly, between the 13th and 20th, Denver and Chicago experienced a notable decrease in average success rates and availability, and a corresponding increase in average retry rates. While the average charge times remained consistent, there was a noticeable increase in the variability of charge times. This suggests that specific stations in these cities may be encountering issues that are affecting performance. Additionally, a slight increase in the standard deviation of both the success rate and retry rate further indicates potential problems at these stations\n",
    "For the short sessions only Chicago is victim of a measurable change in those dates for both average and deviation.\n",
    "\n",
    "It also seems that the increase in standard deviation in charge time in Denver happens a bit earlier though a second peak is observed at the same time as the one in Chicago. Further analysis is necessary to understand why this might be the case. We will try to find the outlier charging stations. \n",
    "\n",
    "Finally, it seems clear that Chicago is more affected by this issue then both Denver and San Jose.\n",
    "\n",
    "Additional data could be used to correlate these findings, such as city power load and power production (even down to a lower granularity like bus data). We could also correlate the data with outside temperature and weather conditions. Additionally, it would be interesting to see if the underperformance aligns with specific days linked to store promotions, holidays, or football games, which could have caused a surge in demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_std_avg_multi(filtered_data,cities=['Chicago'],filter= True,threshold=2.8, outlier_type='low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_std_avg_multi(filtered_data,filter_column='retry_rate',cities=['Chicago'],filter= True,threshold=1, outlier_type='low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the filter option in our function to highlight stations that show a significant deviation from the rolling mean of different metrics. This approach aids in identifying problematic substations. Our initial observations indicate that stations in Chicago have experienced notable issues during the specified time period. However, the data appears noisy, making it challenging to pinpoint underperforming stations due to the presence of generally underperforming stations. This observation suggests the need for a more sophisticated algorithm to accurately identify these stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future we could use other ML based outlier detection techniques like PCA adapted to timeseries or transformer based algorithms to identify the problematic substations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
